{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1143bb66-dbe1-4fc5-9d98-bf65f83a6909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4a4fdf-2f1c-45a6-a1e4-3cac43b44944",
   "metadata": {},
   "source": [
    "# Loading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72ec7fc2-2288-49ce-ba5a-7e3a812d311f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading\n",
      "Completed in 0.08187365531921387s\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading\")\n",
    "path_Ben_linux_1 = \"/home/rubin/Research/data/metadata_IMU_EMG_allgestures_allusers(1).pkl\"\n",
    "\n",
    "start_time = time.time()\n",
    "data_df = pd.read_pickle(path_Ben_linux_1)\n",
    "end_time = time.time()\n",
    "print(f\"Completed in {end_time - start_time}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f304ec3-065f-4e06-83df-10d4f53d546e",
   "metadata": {},
   "source": [
    "# Split Dataset into train and test split, for now just use unimpaired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17b08fd3-a39b-4a47-ae1d-1458671530a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pIDs_impaired = ['P102','P103','P104','P105','P106','P107','P108','P109','P110','P111',\n",
    "       'P112','P114','P115','P116','P118','P119','P121','P122','P123','P124','P125',\n",
    "       'P126','P127','P128', 'P131', 'P132']\n",
    "# note participants P001 and P003 because they dont have duplicate or open gestures\n",
    "pIDs_unimpaired = ['P004','P005','P006','P008','P010','P011']\n",
    "\n",
    "def split_and_preprocess_by_user(data_df, training_users, test_users):\n",
    "    metadata_cols = ['Participant', 'Gesture_ID', 'Gesture_Num']\n",
    "\n",
    "    # Split data by users\n",
    "    train_df = data_df[data_df['Participant'].isin(training_users)]\n",
    "    test_df = data_df[data_df['Participant'].isin(test_users)]\n",
    "\n",
    "    # Subset metadata columns for training and testing sets\n",
    "    train_metadata_df = train_df[metadata_cols].reset_index(drop=True)\n",
    "    test_metadata_df = test_df[metadata_cols].reset_index(drop=True)\n",
    "\n",
    "    # Drop metadata columns from the dataframes\n",
    "    train_df = train_df.drop(metadata_cols, axis=1).reset_index(drop=True)\n",
    "    test_df = test_df.drop(metadata_cols, axis=1).reset_index(drop=True)\n",
    "\n",
    "    # Scale the data\n",
    "    train_scaler = StandardScaler()\n",
    "\n",
    "    # Fit on training data and transform both train and test sets\n",
    "    ppd_train_df = pd.DataFrame(train_scaler.fit_transform(train_df))\n",
    "    ppd_test_df = pd.DataFrame(train_scaler.transform(test_df))\n",
    "\n",
    "\n",
    "    # Split IMU and EMG data\n",
    "    ppd_train_imu_df = ppd_train_df.iloc[:, :72]\n",
    "    ppd_train_emg_df = ppd_train_df.iloc[:, 72:]\n",
    "    ppd_test_imu_df = ppd_test_df.iloc[:, :72]\n",
    "    ppd_test_emg_df = ppd_test_df.iloc[:, 72:]\n",
    "\n",
    "    # Concatenate metadata back to the processed data\n",
    "    ppd_train_imu_df = pd.concat([train_metadata_df, ppd_train_imu_df], axis=1)\n",
    "    ppd_train_emg_df = pd.concat([train_metadata_df, ppd_train_emg_df], axis=1)\n",
    "    ppd_test_imu_df = pd.concat([test_metadata_df, ppd_test_imu_df], axis=1)\n",
    "    ppd_test_emg_df = pd.concat([test_metadata_df, ppd_test_emg_df], axis=1)\n",
    "\n",
    "    return ppd_train_imu_df, ppd_train_emg_df, ppd_test_imu_df, ppd_test_emg_df\n",
    "    \n",
    "ppd_train_imu_df, ppd_train_emg_df, ppd_test_imu_df, ppd_test_emg_df = split_and_preprocess_by_user(data_df, ['P006','P008','P010','P011'], ['P004','P005'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a57853c-2c46-490e-9d30-565968c9f15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25600, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant</th>\n",
       "      <th>Gesture_ID</th>\n",
       "      <th>Gesture_Num</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P006</td>\n",
       "      <td>pan</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.743813</td>\n",
       "      <td>-0.545412</td>\n",
       "      <td>-0.716175</td>\n",
       "      <td>-1.265814</td>\n",
       "      <td>-0.471762</td>\n",
       "      <td>-0.765925</td>\n",
       "      <td>-0.394592</td>\n",
       "      <td>-0.814324</td>\n",
       "      <td>-0.666034</td>\n",
       "      <td>-0.420698</td>\n",
       "      <td>-0.455580</td>\n",
       "      <td>-0.523804</td>\n",
       "      <td>-0.401575</td>\n",
       "      <td>-0.589676</td>\n",
       "      <td>-0.013454</td>\n",
       "      <td>-0.459606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P006</td>\n",
       "      <td>pan</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.739128</td>\n",
       "      <td>-0.566745</td>\n",
       "      <td>-0.712895</td>\n",
       "      <td>-1.261461</td>\n",
       "      <td>-0.495683</td>\n",
       "      <td>-0.638692</td>\n",
       "      <td>-0.286238</td>\n",
       "      <td>-0.812573</td>\n",
       "      <td>-0.666577</td>\n",
       "      <td>-0.409303</td>\n",
       "      <td>-0.452457</td>\n",
       "      <td>-0.523252</td>\n",
       "      <td>-0.485012</td>\n",
       "      <td>-0.601681</td>\n",
       "      <td>-0.052729</td>\n",
       "      <td>-0.466065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P006</td>\n",
       "      <td>pan</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.720411</td>\n",
       "      <td>-0.593631</td>\n",
       "      <td>-0.716057</td>\n",
       "      <td>-1.271174</td>\n",
       "      <td>-0.457003</td>\n",
       "      <td>-0.693394</td>\n",
       "      <td>-0.096152</td>\n",
       "      <td>-0.827890</td>\n",
       "      <td>-0.665456</td>\n",
       "      <td>-0.442158</td>\n",
       "      <td>-0.450521</td>\n",
       "      <td>-0.520637</td>\n",
       "      <td>-0.437734</td>\n",
       "      <td>-0.597538</td>\n",
       "      <td>-0.005312</td>\n",
       "      <td>-0.384134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P006</td>\n",
       "      <td>pan</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.699357</td>\n",
       "      <td>-0.535351</td>\n",
       "      <td>-0.720962</td>\n",
       "      <td>-1.269762</td>\n",
       "      <td>-0.514277</td>\n",
       "      <td>-0.593569</td>\n",
       "      <td>-0.228329</td>\n",
       "      <td>-0.829022</td>\n",
       "      <td>-0.668456</td>\n",
       "      <td>-0.448856</td>\n",
       "      <td>-0.448315</td>\n",
       "      <td>-0.525809</td>\n",
       "      <td>-0.438102</td>\n",
       "      <td>-0.600117</td>\n",
       "      <td>-0.122651</td>\n",
       "      <td>-0.359784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P006</td>\n",
       "      <td>pan</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.700718</td>\n",
       "      <td>-0.510521</td>\n",
       "      <td>-0.719368</td>\n",
       "      <td>-1.256697</td>\n",
       "      <td>-0.573755</td>\n",
       "      <td>-0.743579</td>\n",
       "      <td>-0.303105</td>\n",
       "      <td>-0.826969</td>\n",
       "      <td>-0.669708</td>\n",
       "      <td>-0.450974</td>\n",
       "      <td>-0.446557</td>\n",
       "      <td>-0.531870</td>\n",
       "      <td>-0.434066</td>\n",
       "      <td>-0.604493</td>\n",
       "      <td>-0.286525</td>\n",
       "      <td>-0.374547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Participant Gesture_ID Gesture_Num        72        73        74        75  \\\n",
       "0        P006        pan           6 -0.743813 -0.545412 -0.716175 -1.265814   \n",
       "1        P006        pan           6 -0.739128 -0.566745 -0.712895 -1.261461   \n",
       "2        P006        pan           6 -0.720411 -0.593631 -0.716057 -1.271174   \n",
       "3        P006        pan           6 -0.699357 -0.535351 -0.720962 -1.269762   \n",
       "4        P006        pan           6 -0.700718 -0.510521 -0.719368 -1.256697   \n",
       "\n",
       "         76        77        78        79        80        81        82  \\\n",
       "0 -0.471762 -0.765925 -0.394592 -0.814324 -0.666034 -0.420698 -0.455580   \n",
       "1 -0.495683 -0.638692 -0.286238 -0.812573 -0.666577 -0.409303 -0.452457   \n",
       "2 -0.457003 -0.693394 -0.096152 -0.827890 -0.665456 -0.442158 -0.450521   \n",
       "3 -0.514277 -0.593569 -0.228329 -0.829022 -0.668456 -0.448856 -0.448315   \n",
       "4 -0.573755 -0.743579 -0.303105 -0.826969 -0.669708 -0.450974 -0.446557   \n",
       "\n",
       "         83        84        85        86        87  \n",
       "0 -0.523804 -0.401575 -0.589676 -0.013454 -0.459606  \n",
       "1 -0.523252 -0.485012 -0.601681 -0.052729 -0.466065  \n",
       "2 -0.520637 -0.437734 -0.597538 -0.005312 -0.384134  \n",
       "3 -0.525809 -0.438102 -0.600117 -0.122651 -0.359784  \n",
       "4 -0.531870 -0.434066 -0.604493 -0.286525 -0.374547  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ppd_train_emg_df.shape)\n",
    "ppd_train_emg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3af61c71-7c48-4408-b436-dee2ee09eb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class EMG_IMU_Dataset(Dataset):\n",
    "    def __init__(self, emg_df, imu_df, num_channels_emg=16, num_channels_imu=72, time_units=64):\n",
    "        # Create labels array using only Gesture_ID from EMG data\n",
    "        self.labels = emg_df['Gesture_ID'].values\n",
    "        \n",
    "        # Exclude metadata columns and reshape the EMG and IMU data\n",
    "        emg_data = emg_df.drop(['Participant', 'Gesture_ID', 'Gesture_Num'], axis=1).values\n",
    "        imu_data = imu_df.drop(['Participant', 'Gesture_ID', 'Gesture_Num'], axis=1).values\n",
    "\n",
    "        # EMG data processing: (num_samples, time_units, num_channels_emg)\n",
    "        num_samples_emg = len(emg_data) // time_units\n",
    "        self.emg_data = emg_data.reshape(num_samples_emg, time_units, num_channels_emg).transpose((0, 2, 1))\n",
    "\n",
    "        # IMU data processing: (num_samples, time_units, num_channels_imu)\n",
    "        num_samples_imu = len(imu_data) // time_units\n",
    "        self.imu_data = imu_data.reshape(num_samples_imu, time_units, num_channels_imu).transpose((0, 2, 1))\n",
    "\n",
    "        # Create a dictionary to map each unique Gesture_ID to an integer label\n",
    "        unique_labels = np.unique(self.labels)\n",
    "        self.label_map = {label: i for i, label in enumerate(unique_labels)}\n",
    "        \n",
    "        # Map labels to integers\n",
    "        self.labels = np.array([self.label_map[label] for label in self.labels[:num_samples_emg * time_units:time_units]])\n",
    "\n",
    "        # Create a dictionary to map (Participant, Gesture_ID, Gesture_Num) to index\n",
    "        self.index_map = {(row['Participant'], row['Gesture_ID'], row['Gesture_Num']): idx // time_units \n",
    "                          for idx, row in emg_df.iterrows()}\n",
    "\n",
    "        # Sanity check\n",
    "        print(f\"EMG Data shape: {self.emg_data.shape}\")\n",
    "        print(f\"IMU Data shape: {self.imu_data.shape}\")\n",
    "        print(f\"Labels shape: {self.labels.shape}\")\n",
    "        print(f\"Label mapping: {self.label_map}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.emg_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, tuple):\n",
    "            # Get item by (Participant, Gesture_ID, Gesture_Num)\n",
    "            idx = self.index_map[idx]\n",
    "        \n",
    "        emg_data = torch.tensor(self.emg_data[idx], dtype=torch.float32)\n",
    "        imu_data = torch.tensor(self.imu_data[idx], dtype=torch.float32)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        \n",
    "        return emg_data, imu_data, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "484d838b-8e78-43b2-86e8-c537d14d7df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMG Data shape: (400, 16, 64)\n",
      "IMU Data shape: (400, 72, 64)\n",
      "Labels shape: (400,)\n",
      "Label mapping: {'close': 0, 'delete': 1, 'duplicate': 2, 'move': 3, 'open': 4, 'pan': 5, 'rotate': 6, 'select-single': 7, 'zoom-in': 8, 'zoom-out': 9}\n",
      "EMG Data shape: (200, 16, 64)\n",
      "IMU Data shape: (200, 72, 64)\n",
      "Labels shape: (200,)\n",
      "Label mapping: {'close': 0, 'delete': 1, 'duplicate': 2, 'move': 3, 'open': 4, 'pan': 5, 'rotate': 6, 'select-single': 7, 'zoom-in': 8, 'zoom-out': 9}\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create dataset instances\n",
    "train_dataset = EMG_IMU_Dataset(ppd_train_emg_df, ppd_train_imu_df)\n",
    "test_dataset = EMG_IMU_Dataset(ppd_test_emg_df, ppd_test_imu_df)\n",
    "\n",
    "# Create DataLoader instances\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e48c7ff-173d-4758-a37c-c318fb16c5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class EMG_IMU_CNN(nn.Module):\n",
    "    def __init__(self, num_classes=10, dropout_prob=0.5):\n",
    "        super(EMG_IMU_CNN, self).__init__()\n",
    "\n",
    "        # Convolutional Block for EMG Data (16 channels)\n",
    "        self.emg_conv1 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.emg_bn1 = nn.BatchNorm1d(32)\n",
    "        self.emg_conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.emg_bn2 = nn.BatchNorm1d(64)\n",
    "        self.emg_conv3 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.emg_bn3 = nn.BatchNorm1d(128)\n",
    "        \n",
    "        # Convolutional Block for IMU Data (72 channels)\n",
    "        self.imu_conv1 = nn.Conv1d(in_channels=72, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.imu_bn1 = nn.BatchNorm1d(32)\n",
    "        self.imu_conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.imu_bn2 = nn.BatchNorm1d(64)\n",
    "        self.imu_conv3 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.imu_bn3 = nn.BatchNorm1d(128)\n",
    "        \n",
    "        # Pooling layer (shared)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(p=dropout_prob)\n",
    "\n",
    "        # Fully connected layers after concatenation\n",
    "        self.fc1 = nn.Linear(128 * 8 * 2, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, emg_input, imu_input):\n",
    "        # Forward pass for EMG data\n",
    "        x_emg = torch.relu(self.emg_bn1(self.emg_conv1(emg_input)))\n",
    "        x_emg = self.pool(x_emg)\n",
    "        x_emg = torch.relu(self.emg_bn2(self.emg_conv2(x_emg)))\n",
    "        x_emg = self.pool(x_emg)\n",
    "        x_emg = torch.relu(self.emg_bn3(self.emg_conv3(x_emg)))\n",
    "        x_emg = self.pool(x_emg)\n",
    "        \n",
    "        # Forward pass for IMU data\n",
    "        x_imu = torch.relu(self.imu_bn1(self.imu_conv1(imu_input)))\n",
    "        x_imu = self.pool(x_imu)\n",
    "        x_imu = torch.relu(self.imu_bn2(self.imu_conv2(x_imu)))\n",
    "        x_imu = self.pool(x_imu)\n",
    "        x_imu = torch.relu(self.imu_bn3(self.imu_conv3(x_imu)))\n",
    "        x_imu = self.pool(x_imu)\n",
    "\n",
    "        # Flatten both EMG and IMU outputs\n",
    "        x_emg = torch.flatten(x_emg, start_dim=1)\n",
    "        x_imu = torch.flatten(x_imu, start_dim=1)\n",
    "\n",
    "        # Concatenate the EMG and IMU outputs\n",
    "        x = torch.cat((x_emg, x_imu), dim=1)\n",
    "\n",
    "        # Pass through fully connected layers with dropout\n",
    "        x = self.dropout(torch.relu(self.fc1(x)))\n",
    "        x = self.dropout(torch.relu(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8a02957-6923-4447-9139-d0d9c53c9870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, dataloader, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for emg_data, imu_data, labels in dataloader:\n",
    "        # Move EMG data, IMU data, and labels to the device (GPU or CPU)\n",
    "        emg_data, imu_data, labels = emg_data.to(device), imu_data.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass with both EMG and IMU data\n",
    "        outputs = model(emg_data, imu_data)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update running loss\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Compute accuracy\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    # Calculate final accuracy for the epoch\n",
    "    accuracy = 100. * correct / total\n",
    "    return running_loss / len(dataloader), accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9075ba61-59a0-457f-bd2d-7570ff7549da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for emg_data, imu_data, labels in dataloader:\n",
    "            # Move EMG data, IMU data, and labels to the device (GPU or CPU)\n",
    "            emg_data, imu_data, labels = emg_data.to(device), imu_data.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(emg_data, imu_data)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Update running loss\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Compute accuracy\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    # Compute accuracy over the whole dataset\n",
    "    accuracy = 100. * correct / total\n",
    "    return running_loss / len(dataloader), accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8581741-2b3c-49d7-9617-e89c4d182065",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs, device):   \n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Train the model for one epoch\n",
    "        train_loss, train_acc = train(model, optimizer, train_loader, criterion, device)\n",
    "\n",
    "        end_time = time.time()\n",
    "        epoch_time = end_time - start_time\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"Epoch Time: {epoch_time:.2f} seconds\")\n",
    "        test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "        print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16a51b8b-820c-4fbf-ad98-c7f9ae48ef66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Train Loss: 2.3018, Train Acc: 11.00%\n",
      "Epoch Time: 0.10 seconds\n",
      "Test Loss: 2.2994, Test Acc: 12.50%\n",
      "Epoch 2/100\n",
      "Train Loss: 2.2613, Train Acc: 16.00%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 2.3014, Test Acc: 9.50%\n",
      "Epoch 3/100\n",
      "Train Loss: 2.2145, Train Acc: 20.00%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 2.3122, Test Acc: 9.50%\n",
      "Epoch 4/100\n",
      "Train Loss: 2.1845, Train Acc: 22.25%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 2.3543, Test Acc: 9.00%\n",
      "Epoch 5/100\n",
      "Train Loss: 2.1459, Train Acc: 27.75%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 2.4393, Test Acc: 10.00%\n",
      "Epoch 6/100\n",
      "Train Loss: 2.1154, Train Acc: 31.00%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 2.5352, Test Acc: 11.50%\n",
      "Epoch 7/100\n",
      "Train Loss: 2.0444, Train Acc: 37.25%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 2.6605, Test Acc: 11.50%\n",
      "Epoch 8/100\n",
      "Train Loss: 2.0067, Train Acc: 41.50%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 2.8097, Test Acc: 12.00%\n",
      "Epoch 9/100\n",
      "Train Loss: 1.9557, Train Acc: 41.25%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 2.9106, Test Acc: 10.00%\n",
      "Epoch 10/100\n",
      "Train Loss: 1.8828, Train Acc: 46.00%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 3.0300, Test Acc: 10.50%\n",
      "Epoch 11/100\n",
      "Train Loss: 1.8249, Train Acc: 45.75%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 3.1419, Test Acc: 11.50%\n",
      "Epoch 12/100\n",
      "Train Loss: 1.7861, Train Acc: 45.00%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 3.2587, Test Acc: 12.00%\n",
      "Epoch 13/100\n",
      "Train Loss: 1.7224, Train Acc: 52.50%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 3.3508, Test Acc: 11.00%\n",
      "Epoch 14/100\n",
      "Train Loss: 1.6642, Train Acc: 54.00%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 3.2942, Test Acc: 10.50%\n",
      "Epoch 15/100\n",
      "Train Loss: 1.5589, Train Acc: 58.75%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 3.3529, Test Acc: 12.50%\n",
      "Epoch 16/100\n",
      "Train Loss: 1.4955, Train Acc: 58.25%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 3.4949, Test Acc: 12.00%\n",
      "Epoch 17/100\n",
      "Train Loss: 1.4128, Train Acc: 64.75%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 3.5844, Test Acc: 15.00%\n",
      "Epoch 18/100\n",
      "Train Loss: 1.3408, Train Acc: 69.25%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 3.6388, Test Acc: 16.00%\n",
      "Epoch 19/100\n",
      "Train Loss: 1.2674, Train Acc: 66.50%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 3.6127, Test Acc: 19.50%\n",
      "Epoch 20/100\n",
      "Train Loss: 1.1711, Train Acc: 68.50%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 3.6722, Test Acc: 20.50%\n",
      "Epoch 21/100\n",
      "Train Loss: 1.1185, Train Acc: 72.50%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 3.8204, Test Acc: 17.00%\n",
      "Epoch 22/100\n",
      "Train Loss: 1.0829, Train Acc: 72.75%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 4.0116, Test Acc: 19.50%\n",
      "Epoch 23/100\n",
      "Train Loss: 0.9546, Train Acc: 78.00%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 3.9357, Test Acc: 22.50%\n",
      "Epoch 24/100\n",
      "Train Loss: 0.8809, Train Acc: 77.25%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 4.0156, Test Acc: 22.50%\n",
      "Epoch 25/100\n",
      "Train Loss: 0.7961, Train Acc: 77.75%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 4.0368, Test Acc: 22.50%\n",
      "Epoch 26/100\n",
      "Train Loss: 0.7769, Train Acc: 82.75%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 4.0756, Test Acc: 21.50%\n",
      "Epoch 27/100\n",
      "Train Loss: 0.6920, Train Acc: 83.50%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 4.1023, Test Acc: 20.00%\n",
      "Epoch 28/100\n",
      "Train Loss: 0.6973, Train Acc: 84.75%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 3.9017, Test Acc: 19.50%\n",
      "Epoch 29/100\n",
      "Train Loss: 0.6625, Train Acc: 82.50%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 4.1744, Test Acc: 22.50%\n",
      "Epoch 30/100\n",
      "Train Loss: 0.6176, Train Acc: 81.75%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 4.4384, Test Acc: 23.50%\n",
      "Epoch 31/100\n",
      "Train Loss: 0.5744, Train Acc: 86.00%\n",
      "Epoch Time: 0.09 seconds\n",
      "Test Loss: 4.4440, Test Acc: 21.50%\n",
      "Epoch 32/100\n",
      "Train Loss: 0.4943, Train Acc: 87.00%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 4.4056, Test Acc: 21.00%\n",
      "Epoch 33/100\n",
      "Train Loss: 0.5118, Train Acc: 88.25%\n",
      "Epoch Time: 0.09 seconds\n",
      "Test Loss: 4.4608, Test Acc: 22.00%\n",
      "Epoch 34/100\n",
      "Train Loss: 0.4799, Train Acc: 89.25%\n",
      "Epoch Time: 0.09 seconds\n",
      "Test Loss: 4.5056, Test Acc: 22.50%\n",
      "Epoch 35/100\n",
      "Train Loss: 0.4518, Train Acc: 91.50%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 4.5418, Test Acc: 23.50%\n",
      "Epoch 36/100\n",
      "Train Loss: 0.4023, Train Acc: 90.75%\n",
      "Epoch Time: 0.09 seconds\n",
      "Test Loss: 4.5338, Test Acc: 23.50%\n",
      "Epoch 37/100\n",
      "Train Loss: 0.4344, Train Acc: 91.50%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 4.3439, Test Acc: 24.50%\n",
      "Epoch 38/100\n",
      "Train Loss: 0.3605, Train Acc: 93.00%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 4.5188, Test Acc: 24.00%\n",
      "Epoch 39/100\n",
      "Train Loss: 0.3504, Train Acc: 93.25%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 5.0168, Test Acc: 24.00%\n",
      "Epoch 40/100\n",
      "Train Loss: 0.3354, Train Acc: 95.00%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 5.0660, Test Acc: 23.00%\n",
      "Epoch 41/100\n",
      "Train Loss: 0.3160, Train Acc: 92.50%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 5.1443, Test Acc: 23.00%\n",
      "Epoch 42/100\n",
      "Train Loss: 0.2831, Train Acc: 94.00%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 5.1465, Test Acc: 23.50%\n",
      "Epoch 43/100\n",
      "Train Loss: 0.2337, Train Acc: 96.75%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 5.1628, Test Acc: 23.00%\n",
      "Epoch 44/100\n",
      "Train Loss: 0.2476, Train Acc: 95.25%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 5.2707, Test Acc: 23.00%\n",
      "Epoch 45/100\n",
      "Train Loss: 0.2572, Train Acc: 94.50%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 5.2432, Test Acc: 23.00%\n",
      "Epoch 46/100\n",
      "Train Loss: 0.2370, Train Acc: 96.75%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 5.1592, Test Acc: 24.50%\n",
      "Epoch 47/100\n",
      "Train Loss: 0.2218, Train Acc: 95.50%\n",
      "Epoch Time: 0.09 seconds\n",
      "Test Loss: 5.0238, Test Acc: 24.00%\n",
      "Epoch 48/100\n",
      "Train Loss: 0.2334, Train Acc: 95.00%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 4.9096, Test Acc: 23.50%\n",
      "Epoch 49/100\n",
      "Train Loss: 0.1738, Train Acc: 97.00%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 5.0863, Test Acc: 23.50%\n",
      "Epoch 50/100\n",
      "Train Loss: 0.1828, Train Acc: 96.75%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 5.3020, Test Acc: 22.00%\n",
      "Epoch 51/100\n",
      "Train Loss: 0.1985, Train Acc: 96.75%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 5.3806, Test Acc: 21.50%\n",
      "Epoch 52/100\n",
      "Train Loss: 0.1745, Train Acc: 97.50%\n",
      "Epoch Time: 0.09 seconds\n",
      "Test Loss: 5.3532, Test Acc: 21.00%\n",
      "Epoch 53/100\n",
      "Train Loss: 0.1770, Train Acc: 98.25%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 5.0142, Test Acc: 23.00%\n",
      "Epoch 54/100\n",
      "Train Loss: 0.1516, Train Acc: 96.75%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 4.8326, Test Acc: 23.00%\n",
      "Epoch 55/100\n",
      "Train Loss: 0.1629, Train Acc: 98.00%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 4.8324, Test Acc: 23.50%\n",
      "Epoch 56/100\n",
      "Train Loss: 0.1320, Train Acc: 97.75%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 5.2104, Test Acc: 23.50%\n",
      "Epoch 57/100\n",
      "Train Loss: 0.1286, Train Acc: 99.00%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 5.3224, Test Acc: 23.50%\n",
      "Epoch 58/100\n",
      "Train Loss: 0.1414, Train Acc: 97.75%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 5.4499, Test Acc: 23.50%\n",
      "Epoch 59/100\n",
      "Train Loss: 0.1257, Train Acc: 98.25%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 5.6303, Test Acc: 23.50%\n",
      "Epoch 60/100\n",
      "Train Loss: 0.1110, Train Acc: 98.75%\n",
      "Epoch Time: 0.09 seconds\n",
      "Test Loss: 5.5430, Test Acc: 22.50%\n",
      "Epoch 61/100\n",
      "Train Loss: 0.1145, Train Acc: 98.25%\n",
      "Epoch Time: 0.09 seconds\n",
      "Test Loss: 5.4297, Test Acc: 22.00%\n",
      "Epoch 62/100\n",
      "Train Loss: 0.1113, Train Acc: 98.00%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 5.3720, Test Acc: 21.50%\n",
      "Epoch 63/100\n",
      "Train Loss: 0.0887, Train Acc: 99.25%\n",
      "Epoch Time: 0.09 seconds\n",
      "Test Loss: 5.5870, Test Acc: 22.50%\n",
      "Epoch 64/100\n",
      "Train Loss: 0.0943, Train Acc: 99.25%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 5.4955, Test Acc: 22.50%\n",
      "Epoch 65/100\n",
      "Train Loss: 0.0921, Train Acc: 98.50%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 5.3691, Test Acc: 22.50%\n",
      "Epoch 66/100\n",
      "Train Loss: 0.1105, Train Acc: 98.50%\n",
      "Epoch Time: 0.09 seconds\n",
      "Test Loss: 5.3069, Test Acc: 22.50%\n",
      "Epoch 67/100\n",
      "Train Loss: 0.0734, Train Acc: 99.75%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 5.3036, Test Acc: 21.50%\n",
      "Epoch 68/100\n",
      "Train Loss: 0.0912, Train Acc: 99.00%\n",
      "Epoch Time: 0.09 seconds\n",
      "Test Loss: 5.4767, Test Acc: 22.50%\n",
      "Epoch 69/100\n",
      "Train Loss: 0.0780, Train Acc: 99.25%\n",
      "Epoch Time: 0.09 seconds\n",
      "Test Loss: 5.6011, Test Acc: 21.50%\n",
      "Epoch 70/100\n",
      "Train Loss: 0.0947, Train Acc: 97.75%\n",
      "Epoch Time: 0.09 seconds\n",
      "Test Loss: 5.5936, Test Acc: 22.50%\n",
      "Epoch 71/100\n",
      "Train Loss: 0.0763, Train Acc: 99.00%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 5.5851, Test Acc: 22.50%\n",
      "Epoch 72/100\n",
      "Train Loss: 0.0726, Train Acc: 99.25%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 5.6461, Test Acc: 23.00%\n",
      "Epoch 73/100\n",
      "Train Loss: 0.0745, Train Acc: 99.50%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 5.5206, Test Acc: 23.00%\n",
      "Epoch 74/100\n",
      "Train Loss: 0.0906, Train Acc: 98.75%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 5.2884, Test Acc: 22.50%\n",
      "Epoch 75/100\n",
      "Train Loss: 0.0664, Train Acc: 99.50%\n",
      "Epoch Time: 0.09 seconds\n",
      "Test Loss: 5.4817, Test Acc: 21.50%\n",
      "Epoch 76/100\n",
      "Train Loss: 0.0656, Train Acc: 99.50%\n",
      "Epoch Time: 0.09 seconds\n",
      "Test Loss: 5.5966, Test Acc: 22.00%\n",
      "Epoch 77/100\n",
      "Train Loss: 0.0835, Train Acc: 99.00%\n",
      "Epoch Time: 0.09 seconds\n",
      "Test Loss: 5.5536, Test Acc: 21.00%\n",
      "Epoch 78/100\n",
      "Train Loss: 0.0659, Train Acc: 98.50%\n",
      "Epoch Time: 0.09 seconds\n",
      "Test Loss: 5.4401, Test Acc: 20.50%\n",
      "Epoch 79/100\n",
      "Train Loss: 0.0632, Train Acc: 99.25%\n",
      "Epoch Time: 0.09 seconds\n",
      "Test Loss: 5.5165, Test Acc: 20.50%\n",
      "Epoch 80/100\n",
      "Train Loss: 0.0677, Train Acc: 99.75%\n",
      "Epoch Time: 0.09 seconds\n",
      "Test Loss: 5.5038, Test Acc: 20.50%\n",
      "Epoch 81/100\n",
      "Train Loss: 0.0453, Train Acc: 100.00%\n",
      "Epoch Time: 0.09 seconds\n",
      "Test Loss: 5.7915, Test Acc: 21.00%\n",
      "Epoch 82/100\n",
      "Train Loss: 0.0629, Train Acc: 98.75%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 5.8086, Test Acc: 22.00%\n",
      "Epoch 83/100\n",
      "Train Loss: 0.0453, Train Acc: 100.00%\n",
      "Epoch Time: 0.09 seconds\n",
      "Test Loss: 5.8610, Test Acc: 21.50%\n",
      "Epoch 84/100\n",
      "Train Loss: 0.0525, Train Acc: 99.25%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 5.7465, Test Acc: 22.00%\n",
      "Epoch 85/100\n",
      "Train Loss: 0.0464, Train Acc: 98.75%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 5.9490, Test Acc: 22.50%\n",
      "Epoch 86/100\n",
      "Train Loss: 0.0690, Train Acc: 99.25%\n",
      "Epoch Time: 0.09 seconds\n",
      "Test Loss: 5.9907, Test Acc: 22.00%\n",
      "Epoch 87/100\n",
      "Train Loss: 0.0578, Train Acc: 99.50%\n",
      "Epoch Time: 0.09 seconds\n",
      "Test Loss: 5.9120, Test Acc: 21.50%\n",
      "Epoch 88/100\n",
      "Train Loss: 0.0381, Train Acc: 99.75%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 5.9547, Test Acc: 21.50%\n",
      "Epoch 89/100\n",
      "Train Loss: 0.0467, Train Acc: 99.75%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 5.7977, Test Acc: 22.00%\n",
      "Epoch 90/100\n",
      "Train Loss: 0.0466, Train Acc: 99.50%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 5.7570, Test Acc: 21.50%\n",
      "Epoch 91/100\n",
      "Train Loss: 0.0497, Train Acc: 99.75%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 5.6699, Test Acc: 21.50%\n",
      "Epoch 92/100\n",
      "Train Loss: 0.0333, Train Acc: 100.00%\n",
      "Epoch Time: 0.09 seconds\n",
      "Test Loss: 5.6492, Test Acc: 21.50%\n",
      "Epoch 93/100\n",
      "Train Loss: 0.0448, Train Acc: 99.25%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 5.7836, Test Acc: 21.50%\n",
      "Epoch 94/100\n",
      "Train Loss: 0.0326, Train Acc: 100.00%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 5.9357, Test Acc: 21.00%\n",
      "Epoch 95/100\n",
      "Train Loss: 0.0351, Train Acc: 99.75%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 6.0083, Test Acc: 21.50%\n",
      "Epoch 96/100\n",
      "Train Loss: 0.0350, Train Acc: 99.75%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 6.1430, Test Acc: 22.00%\n",
      "Epoch 97/100\n",
      "Train Loss: 0.0419, Train Acc: 99.50%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 6.1186, Test Acc: 22.50%\n",
      "Epoch 98/100\n",
      "Train Loss: 0.0383, Train Acc: 99.75%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 6.1540, Test Acc: 22.00%\n",
      "Epoch 99/100\n",
      "Train Loss: 0.0388, Train Acc: 99.25%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 5.8845, Test Acc: 21.00%\n",
      "Epoch 100/100\n",
      "Train Loss: 0.0267, Train Acc: 99.75%\n",
      "Epoch Time: 0.08 seconds\n",
      "Test Loss: 5.8405, Test Acc: 19.50%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize EMG_IMU_CNN model and move it to the device\n",
    "emgimu_model = EMG_IMU_CNN().to(device)\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 100\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(emgimu_model.parameters(), lr=0.0001)\n",
    "\n",
    "# Train the EMG-IMU model\n",
    "train_model(emgimu_model, train_loader, test_loader, criterion, optimizer, num_epochs, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50fd19c-54a3-475f-a320-44b7a98a04a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2c501b-7a4a-4a1e-960f-355d61fba1b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aa5cb6-17e8-47ea-bc48-afaf7c25da66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
