{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1143bb66-dbe1-4fc5-9d98-bf65f83a6909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4a4fdf-2f1c-45a6-a1e4-3cac43b44944",
   "metadata": {},
   "source": [
    "# Loading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72ec7fc2-2288-49ce-ba5a-7e3a812d311f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading\n",
      "Completed in 0.19122672080993652s\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading\")\n",
    "path_Ben_linux_1 = \"/home/rubin/Research/data/metadata_IMU_EMG_allgestures_allusers(1).pkl\"\n",
    "\n",
    "start_time = time.time()\n",
    "data_df = pd.read_pickle(path_Ben_linux_1)\n",
    "end_time = time.time()\n",
    "print(f\"Completed in {end_time - start_time}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c81305ea-6141-49fb-937d-90d79ba5321a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading\n",
      "Completed in 0.4583280086517334s\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading\")\n",
    "path_Ben_linux = \"/home/rubin/Research/data/metadata_IMU_EMG_allgestures_allusers.pkl\"\n",
    "\n",
    "start_time = time.time()\n",
    "data_df1 = pd.read_pickle(path_Ben_linux)\n",
    "end_time = time.time()\n",
    "print(f\"Completed in {end_time - start_time}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d101cc5c-8b6f-44ad-9652-f01e47329e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Participant Gesture_ID Gesture_Num   IMU1_ax   IMU1_ay   IMU1_az   IMU1_vx  \\\n",
      "0        P102        pan           1  0.341797 -0.939941  0.000977 -0.007450   \n",
      "1        P102        pan           1  0.336178 -0.963185  0.003898  0.009595   \n",
      "2        P102        pan           1  0.353539 -0.963704  0.011711  0.095966   \n",
      "3        P102        pan           1  0.352841 -0.950288  0.011509  0.058836   \n",
      "4        P102        pan           1  0.372621 -0.991273  0.029847  0.293946   \n",
      "\n",
      "    IMU1_vy   IMU1_vz   IMU2_ax  ...      EMG7      EMG8      EMG9     EMG10  \\\n",
      "0 -0.192625  0.005321 -0.380859  ...  0.000002  0.000002  0.000003  0.000020   \n",
      "1 -0.190446 -0.026116 -0.394547  ...  0.000003  0.000003  0.000003  0.000014   \n",
      "2 -0.205480 -0.155563 -0.398406  ...  0.000003  0.000003  0.000004  0.000007   \n",
      "3 -0.184871 -0.083567 -0.389230  ...  0.000003  0.000003  0.000006  0.000005   \n",
      "4 -0.178756 -0.281361 -0.396043  ...  0.000003  0.000002  0.000008  0.000003   \n",
      "\n",
      "      EMG11     EMG12     EMG13     EMG14     EMG15     EMG16  \n",
      "0  0.000004  0.000004  0.000002  0.000009  0.000001  0.000002  \n",
      "1  0.000007  0.000007  0.000002  0.000017  0.000001  0.000002  \n",
      "2  0.000004  0.000005  0.000003  0.000020  0.000003  0.000002  \n",
      "3  0.000004  0.000003  0.000004  0.000015  0.000003  0.000003  \n",
      "4  0.000007  0.000022  0.000004  0.000017  0.000002  0.000003  \n",
      "\n",
      "[5 rows x 91 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f70259c-278c-42b1-84a0-527061561c1e",
   "metadata": {},
   "source": [
    "# Compare Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "535da1dd-1ea3-42cb-b101-0610a220ca0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'single-pinch', 'gesture-1', 'point-and-pinch', 'gesture-3', 'double-clench', 'gesture-2', 'double-pinch', 'pinch-and-scroll', 'gesture-5', 'two-handed-tap', 'air-tap', 'normal', 'gesture-4', 'shake-and-release', 'palm-pinch', 'range-of-motion', 'single-clench', 'frequency'}\n"
     ]
    }
   ],
   "source": [
    "print(set(data_df['Gesture_ID'].unique()) ^ set(data_df1['Gesture_ID'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e670d549-9c00-40e0-8951-00fef64fe1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "print(set(data_df['Gesture_ID'].unique()) - set(data_df1['Gesture_ID'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b5d711e-0e31-4e27-adf3-37324e021046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gesture-4', 'single-pinch', 'gesture-1', 'shake-and-release', 'point-and-pinch', 'gesture-3', 'double-clench', 'palm-pinch', 'gesture-2', 'range-of-motion', 'single-clench', 'double-pinch', 'pinch-and-scroll', 'gesture-5', 'two-handed-tap', 'frequency', 'air-tap', 'normal'}\n"
     ]
    }
   ],
   "source": [
    "print(set(data_df1['Gesture_ID'].unique()) - set(data_df['Gesture_ID'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5afcd708-a236-4037-aefd-0a6ee5e8e3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'P131'}\n"
     ]
    }
   ],
   "source": [
    "print(set(data_df['Participant'].unique()) - set(data_df1['Participant'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24adc52c-6d44-4688-ba9d-c2b987f0355f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "print(set(data_df1['Participant'].unique()) - set(data_df['Participant'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aba12d41-b2e3-4496-8228-4ebc018b1989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426752, 91) (204800, 91)\n"
     ]
    }
   ],
   "source": [
    "print(data_df1.shape, data_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "884cac03-ee16-4f65-b385-bc15e279dea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pan' 'duplicate' 'gesture-1' 'gesture-2' 'gesture-3' 'gesture-4'\n",
      " 'gesture-5' 'normal' 'frequency' 'range-of-motion' 'zoom-out' 'zoom-in'\n",
      " 'move' 'rotate' 'select-single' 'delete' 'close' 'open' 'two-handed-tap'\n",
      " 'point-and-pinch' 'pinch-and-scroll' 'air-tap' 'palm-pinch'\n",
      " 'double-pinch' 'single-pinch' 'single-clench' 'shake-and-release'\n",
      " 'double-clench']\n"
     ]
    }
   ],
   "source": [
    "print(data_df1['Gesture_ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ca6f909-9470-4a1a-b3cd-0605ea373637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P102' 'P103' 'P104' 'P105' 'P106' 'P107' 'P108' 'P109' 'P110' 'P111'\n",
      " 'P112' 'P114' 'P115' 'P116' 'P118' 'P119' 'P121' 'P122' 'P123' 'P124'\n",
      " 'P125' 'P126' 'P127' 'P128' 'P132' 'P004' 'P005' 'P006' 'P008' 'P010'\n",
      " 'P011']\n"
     ]
    }
   ],
   "source": [
    "print(data_df1['Participant'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabce889-bd41-4ce8-a757-3df5f81892d0",
   "metadata": {},
   "source": [
    "### df has one extra user and less gestures but I'll be using it for now because these are the standard gestures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f304ec3-065f-4e06-83df-10d4f53d546e",
   "metadata": {},
   "source": [
    "# Split Dataset into train and test split, for now just use unimpaired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a2037b50-c24e-4fae-805b-fec1def11ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_cols = ['Participant', 'Gesture_ID', 'Gesture_Num']\n",
    "metadata_cols_df = data_df[metadata_cols]\n",
    "X = data_df.drop(metadata_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "17b08fd3-a39b-4a47-ae1d-1458671530a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pIDs_impaired = ['P102','P103','P104','P105','P106','P107','P108','P109','P110','P111',\n",
    "       'P112','P114','P115','P116','P118','P119','P121','P122','P123','P124','P125',\n",
    "       'P126','P127','P128', 'P131', 'P132']\n",
    "# note participants P001 and P003 because they dont have duplicate or open gestures\n",
    "pIDs_unimpaired = ['P004','P005','P006','P008','P010','P011']\n",
    "\n",
    "def split_and_preprocess_by_user(data_df, training_users, test_users):\n",
    "    metadata_cols = ['Participant', 'Gesture_ID', 'Gesture_Num']\n",
    "\n",
    "    # Split data by users\n",
    "    train_df = data_df[data_df['Participant'].isin(training_users)]\n",
    "    test_df = data_df[data_df['Participant'].isin(test_users)]\n",
    "\n",
    "    # Subset metadata columns for training and testing sets\n",
    "    train_metadata_df = train_df[metadata_cols].reset_index(drop=True)\n",
    "    test_metadata_df = test_df[metadata_cols].reset_index(drop=True)\n",
    "\n",
    "    # Drop metadata columns from the dataframes\n",
    "    train_df = train_df.drop(metadata_cols, axis=1).reset_index(drop=True)\n",
    "    test_df = test_df.drop(metadata_cols, axis=1).reset_index(drop=True)\n",
    "\n",
    "    # Scale the data\n",
    "    train_scaler = StandardScaler()\n",
    "    test_scaler = StandardScaler()\n",
    "\n",
    "    ppd_train_df = pd.DataFrame(train_scaler.fit_transform(train_df))\n",
    "    ppd_test_df = pd.DataFrame(test_scaler.fit_transform(test_df))\n",
    "\n",
    "    # Split IMU and EMG data\n",
    "    ppd_train_imu_df = ppd_train_df.iloc[:, :72]\n",
    "    ppd_train_emg_df = ppd_train_df.iloc[:, 72:]\n",
    "    ppd_test_imu_df = ppd_test_df.iloc[:, :72]\n",
    "    ppd_test_emg_df = ppd_test_df.iloc[:, 72:]\n",
    "\n",
    "    # Concatenate metadata back to the processed data\n",
    "    ppd_train_imu_df = pd.concat([train_metadata_df, ppd_train_imu_df], axis=1)\n",
    "    ppd_train_emg_df = pd.concat([train_metadata_df, ppd_train_emg_df], axis=1)\n",
    "    ppd_test_imu_df = pd.concat([test_metadata_df, ppd_test_imu_df], axis=1)\n",
    "    ppd_test_emg_df = pd.concat([test_metadata_df, ppd_test_emg_df], axis=1)\n",
    "\n",
    "    return ppd_train_imu_df, ppd_train_emg_df, ppd_test_imu_df, ppd_test_emg_df\n",
    "    \n",
    "ppd_train_imu_df, ppd_train_emg_df, ppd_test_imu_df, ppd_test_emg_df = split_and_preprocess_by_user(data_df, ['P006','P008','P010','P011'], ['P004','P005'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7a57853c-2c46-490e-9d30-565968c9f15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25600, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant</th>\n",
       "      <th>Gesture_ID</th>\n",
       "      <th>Gesture_Num</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P006</td>\n",
       "      <td>pan</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.743813</td>\n",
       "      <td>-0.545412</td>\n",
       "      <td>-0.716175</td>\n",
       "      <td>-1.265814</td>\n",
       "      <td>-0.471762</td>\n",
       "      <td>-0.765925</td>\n",
       "      <td>-0.394592</td>\n",
       "      <td>-0.814324</td>\n",
       "      <td>-0.666034</td>\n",
       "      <td>-0.420698</td>\n",
       "      <td>-0.455580</td>\n",
       "      <td>-0.523804</td>\n",
       "      <td>-0.401575</td>\n",
       "      <td>-0.589676</td>\n",
       "      <td>-0.013454</td>\n",
       "      <td>-0.459606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P006</td>\n",
       "      <td>pan</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.739128</td>\n",
       "      <td>-0.566745</td>\n",
       "      <td>-0.712895</td>\n",
       "      <td>-1.261461</td>\n",
       "      <td>-0.495683</td>\n",
       "      <td>-0.638692</td>\n",
       "      <td>-0.286238</td>\n",
       "      <td>-0.812573</td>\n",
       "      <td>-0.666577</td>\n",
       "      <td>-0.409303</td>\n",
       "      <td>-0.452457</td>\n",
       "      <td>-0.523252</td>\n",
       "      <td>-0.485012</td>\n",
       "      <td>-0.601681</td>\n",
       "      <td>-0.052729</td>\n",
       "      <td>-0.466065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P006</td>\n",
       "      <td>pan</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.720411</td>\n",
       "      <td>-0.593631</td>\n",
       "      <td>-0.716057</td>\n",
       "      <td>-1.271174</td>\n",
       "      <td>-0.457003</td>\n",
       "      <td>-0.693394</td>\n",
       "      <td>-0.096152</td>\n",
       "      <td>-0.827890</td>\n",
       "      <td>-0.665456</td>\n",
       "      <td>-0.442158</td>\n",
       "      <td>-0.450521</td>\n",
       "      <td>-0.520637</td>\n",
       "      <td>-0.437734</td>\n",
       "      <td>-0.597538</td>\n",
       "      <td>-0.005312</td>\n",
       "      <td>-0.384134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P006</td>\n",
       "      <td>pan</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.699357</td>\n",
       "      <td>-0.535351</td>\n",
       "      <td>-0.720962</td>\n",
       "      <td>-1.269762</td>\n",
       "      <td>-0.514277</td>\n",
       "      <td>-0.593569</td>\n",
       "      <td>-0.228329</td>\n",
       "      <td>-0.829022</td>\n",
       "      <td>-0.668456</td>\n",
       "      <td>-0.448856</td>\n",
       "      <td>-0.448315</td>\n",
       "      <td>-0.525809</td>\n",
       "      <td>-0.438102</td>\n",
       "      <td>-0.600117</td>\n",
       "      <td>-0.122651</td>\n",
       "      <td>-0.359784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P006</td>\n",
       "      <td>pan</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.700718</td>\n",
       "      <td>-0.510521</td>\n",
       "      <td>-0.719368</td>\n",
       "      <td>-1.256697</td>\n",
       "      <td>-0.573755</td>\n",
       "      <td>-0.743579</td>\n",
       "      <td>-0.303105</td>\n",
       "      <td>-0.826969</td>\n",
       "      <td>-0.669708</td>\n",
       "      <td>-0.450974</td>\n",
       "      <td>-0.446557</td>\n",
       "      <td>-0.531870</td>\n",
       "      <td>-0.434066</td>\n",
       "      <td>-0.604493</td>\n",
       "      <td>-0.286525</td>\n",
       "      <td>-0.374547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Participant Gesture_ID Gesture_Num        72        73        74        75  \\\n",
       "0        P006        pan           6 -0.743813 -0.545412 -0.716175 -1.265814   \n",
       "1        P006        pan           6 -0.739128 -0.566745 -0.712895 -1.261461   \n",
       "2        P006        pan           6 -0.720411 -0.593631 -0.716057 -1.271174   \n",
       "3        P006        pan           6 -0.699357 -0.535351 -0.720962 -1.269762   \n",
       "4        P006        pan           6 -0.700718 -0.510521 -0.719368 -1.256697   \n",
       "\n",
       "         76        77        78        79        80        81        82  \\\n",
       "0 -0.471762 -0.765925 -0.394592 -0.814324 -0.666034 -0.420698 -0.455580   \n",
       "1 -0.495683 -0.638692 -0.286238 -0.812573 -0.666577 -0.409303 -0.452457   \n",
       "2 -0.457003 -0.693394 -0.096152 -0.827890 -0.665456 -0.442158 -0.450521   \n",
       "3 -0.514277 -0.593569 -0.228329 -0.829022 -0.668456 -0.448856 -0.448315   \n",
       "4 -0.573755 -0.743579 -0.303105 -0.826969 -0.669708 -0.450974 -0.446557   \n",
       "\n",
       "         83        84        85        86        87  \n",
       "0 -0.523804 -0.401575 -0.589676 -0.013454 -0.459606  \n",
       "1 -0.523252 -0.485012 -0.601681 -0.052729 -0.466065  \n",
       "2 -0.520637 -0.437734 -0.597538 -0.005312 -0.384134  \n",
       "3 -0.525809 -0.438102 -0.600117 -0.122651 -0.359784  \n",
       "4 -0.531870 -0.434066 -0.604493 -0.286525 -0.374547  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ppd_train_emg_df.shape)\n",
    "ppd_train_emg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "3af61c71-7c48-4408-b436-dee2ee09eb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (400, 64, 16)\n",
      "Labels shape: (400,)\n",
      "Label mapping: {'close': 0, 'delete': 1, 'duplicate': 2, 'move': 3, 'open': 4, 'pan': 5, 'rotate': 6, 'select-single': 7, 'zoom-in': 8, 'zoom-out': 9}\n",
      "True\n",
      "torch.Size([64, 16])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class EMGDataset(Dataset):\n",
    "    def __init__(self, data_df, num_channels=16, time_units=64):\n",
    "        # Create labels array using only Gesture_ID\n",
    "        self.labels = data_df['Gesture_ID'].values\n",
    "        \n",
    "        # Exclude metadata columns and reshape the data to (num_samples, time_units, num_channels)\n",
    "        self.data = data_df.drop(['Participant', 'Gesture_ID', 'Gesture_Num'], axis=1).values\n",
    "        num_samples = len(self.data) // time_units\n",
    "        self.data = self.data.reshape(num_samples, time_units, num_channels)\n",
    "\n",
    "        # Create a dictionary to map each unique Gesture_ID to an integer label\n",
    "        unique_labels = np.unique(self.labels)\n",
    "        self.label_map = {label: i for i, label in enumerate(unique_labels)}\n",
    "        # Map labels to integers\n",
    "        self.labels = np.array([self.label_map[label] for label in self.labels[:num_samples * time_units:time_units]])\n",
    "\n",
    "        # Create a dictionary to map (Participant, Gesture_ID, Gesture_Num) to index\n",
    "        self.index_map = {(row['Participant'], row['Gesture_ID'], row['Gesture_Num']): idx // time_units \n",
    "                          for idx, row in data_df.iterrows()}\n",
    "\n",
    "        # Sanity check\n",
    "        print(f\"Data shape: {self.data.shape}\")\n",
    "        print(f\"Labels shape: {self.labels.shape}\")\n",
    "        print(f\"Label mapping: {self.label_map}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, tuple):\n",
    "            # Get item by (Participant, Gesture_ID, Gesture_Num)\n",
    "            idx = self.index_map[idx]\n",
    "        data = torch.tensor(self.data[idx], dtype=torch.float32)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return data, label\n",
    "\n",
    "\n",
    "dataset = EMGDataset(ppd_train_emg_df)\n",
    "\n",
    "original_data = ppd_train_emg_df[(ppd_train_emg_df['Participant'] == 'P008') &\n",
    "                                (ppd_train_emg_df['Gesture_ID'] == 'pan') &\n",
    "                                (ppd_train_emg_df['Gesture_Num'] == '6')]\n",
    "\n",
    "torch_data, torch_label = dataset[('P008', 'pan', '6')]\n",
    "\n",
    "# Get the corresponding data from the original dataset\n",
    "original_data = original_data.drop(['Participant', 'Gesture_ID', 'Gesture_Num'], axis=1).values\n",
    "\n",
    "# Check if the data is the same\n",
    "print(np.allclose(original_data, torch_data))\n",
    "print(torch_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "484d838b-8e78-43b2-86e8-c537d14d7df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (400, 64, 16)\n",
      "Labels shape: (400,)\n",
      "Label mapping: {'close': 0, 'delete': 1, 'duplicate': 2, 'move': 3, 'open': 4, 'pan': 5, 'rotate': 6, 'select-single': 7, 'zoom-in': 8, 'zoom-out': 9}\n",
      "Data shape: (200, 64, 16)\n",
      "Labels shape: (200,)\n",
      "Label mapping: {'close': 0, 'delete': 1, 'duplicate': 2, 'move': 3, 'open': 4, 'pan': 5, 'rotate': 6, 'select-single': 7, 'zoom-in': 8, 'zoom-out': 9}\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create dataset instances\n",
    "train_dataset = EMGDataset(ppd_train_emg_df)\n",
    "test_dataset = EMGDataset(ppd_test_emg_df)\n",
    "\n",
    "# Create DataLoader instances\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "4e48c7ff-173d-4758-a37c-c318fb16c5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class EMGCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(EMGCNN, self).__init__()\n",
    "        \n",
    "        # Convolutional Block 1\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 3), padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        \n",
    "        # Convolutional Block 2\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1)\n",
    "        \n",
    "        # Convolutional Block 3\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), padding=1)\n",
    "        \n",
    "        # After applying three convolutional blocks and pooling, \n",
    "        # the input size reduces; calculate the flattened size\n",
    "        # Assuming input size is (1, 64, 16):\n",
    "        # After pool1 -> (32, 32, 8)\n",
    "        # After pool2 -> (64, 16, 4)\n",
    "        # After pool3 -> (128, 8, 2)\n",
    "\n",
    "        self.fc1 = nn.Linear(2048,256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(\"Input shape:\", x.shape)\n",
    "        x = x.unsqueeze(1)  # Add channel dimension\n",
    "        # print(\"After unsqueeze:\", x.shape)  # Shape: [batch_size, 1, height, width]\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        # print(\"After conv1:\", x.shape)\n",
    "        x = self.pool(x)\n",
    "        # print(\"After pool1:\", x.shape)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        # print(\"After conv2:\", x.shape)\n",
    "        x = self.pool(x)\n",
    "        # print(\"After pool2:\", x.shape)\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        # print(\"After conv3:\", x.shape)\n",
    "        x = self.pool(x)\n",
    "        # print(\"After pool3:\", x.shape)\n",
    "        \n",
    "        # Flatten the tensor for the fully connected layers\n",
    "        # print(\"Shape before flattening:\", x.shape)\n",
    "        x = torch.flatten(x, start_dim=1) \n",
    "        # print(\"Shape after flattening:\", x.shape)\n",
    "        \n",
    "        x = torch.relu(self.fc1(x))  # Now this should work without an error\n",
    "        # print(\"After fc1:\", x.shape)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        # print(\"After fc2:\", x.shape)\n",
    "        x = self.fc3(x)\n",
    "        # print(\"After fc3:\", x.shape)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "16a51b8b-820c-4fbf-ad98-c7f9ae48ef66",
   "metadata": {},
   "outputs": [],
   "source": [
    "emg_model = EMGCNN(10)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(emg_model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "d8a02957-6923-4447-9139-d0d9c53c9870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, dataloader, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for data, labels in dataloader:\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    accuracy = 100. * correct / total\n",
    "    return running_loss / len(dataloader), accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "9075ba61-59a0-457f-bd2d-7570ff7549da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, labels in dataloader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    accuracy = 100. * correct / total\n",
    "    return running_loss / len(dataloader), accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "f8581741-2b3c-49d7-9617-e89c4d182065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      "Train Loss: 2.3058, Train Acc: 9.75%, Test Loss: 2.2972, Test Acc: 10.00%\n",
      "Epoch 2/10:\n",
      "Train Loss: 2.3058, Train Acc: 9.75%, Test Loss: 2.2972, Test Acc: 10.00%\n",
      "Epoch 3/10:\n",
      "Train Loss: 2.3058, Train Acc: 9.75%, Test Loss: 2.2972, Test Acc: 10.00%\n",
      "Epoch 4/10:\n",
      "Train Loss: 2.3058, Train Acc: 9.75%, Test Loss: 2.2972, Test Acc: 10.00%\n",
      "Epoch 5/10:\n",
      "Train Loss: 2.3058, Train Acc: 9.75%, Test Loss: 2.2972, Test Acc: 10.00%\n",
      "Epoch 6/10:\n",
      "Train Loss: 2.3058, Train Acc: 9.75%, Test Loss: 2.2972, Test Acc: 10.00%\n",
      "Epoch 7/10:\n",
      "Train Loss: 2.3058, Train Acc: 9.75%, Test Loss: 2.2972, Test Acc: 10.00%\n",
      "Epoch 8/10:\n",
      "Train Loss: 2.3058, Train Acc: 9.75%, Test Loss: 2.2972, Test Acc: 10.00%\n",
      "Epoch 9/10:\n",
      "Train Loss: 2.3058, Train Acc: 9.75%, Test Loss: 2.2972, Test Acc: 10.00%\n",
      "Epoch 10/10:\n",
      "Train Loss: 2.3058, Train Acc: 9.75%, Test Loss: 2.2972, Test Acc: 10.00%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "emg_model = EMGCNN().to(device)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train(emg_model, optimizer, train_loader, criterion, device)\n",
    "    test_loss, test_acc = evaluate(emg_model, test_loader, criterion, device)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}:')\n",
    "    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "32e1ab1f-3127-4e22-af6e-9cd04b8cc127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMGCNN(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=2048, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(emg_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
