{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1143bb66-dbe1-4fc5-9d98-bf65f83a6909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4a4fdf-2f1c-45a6-a1e4-3cac43b44944",
   "metadata": {},
   "source": [
    "# Loading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72ec7fc2-2288-49ce-ba5a-7e3a812d311f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading\n",
      "Completed in 0.1108553409576416s\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading\")\n",
    "path_Ben_linux_1 = \"/home/rubin/Research/data/metadata_IMU_EMG_allgestures_allusers(1).pkl\"\n",
    "\n",
    "start_time = time.time()\n",
    "data_df = pd.read_pickle(path_Ben_linux_1)\n",
    "end_time = time.time()\n",
    "print(f\"Completed in {end_time - start_time}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f304ec3-065f-4e06-83df-10d4f53d546e",
   "metadata": {},
   "source": [
    "# Split Dataset into train and test split, for now just use unimpaired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17b08fd3-a39b-4a47-ae1d-1458671530a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impaired participants\n",
    "pIDs_impaired = ['P102', 'P103', 'P104', 'P105', 'P106', 'P107', 'P108', 'P109', 'P110', 'P111',\n",
    "                 'P112', 'P114', 'P115', 'P116', 'P118', 'P119', 'P121', 'P122', 'P123', 'P124', \n",
    "                 'P125', 'P126', 'P127', 'P128', 'P131', 'P132']\n",
    "\n",
    "# Unimpaired participants\n",
    "pIDs_unimpaired = ['P004', 'P005', 'P006', 'P008', 'P010', 'P011']\n",
    "\n",
    "def split_and_preprocess_by_user(data_df, pIDs_impaired, pIDs_unimpaired, test_size=0.2):\n",
    "    # Split impaired and unimpaired participants into train and test sets\n",
    "    impaired_train, impaired_test = train_test_split(pIDs_impaired, test_size=test_size, random_state=42)\n",
    "    unimpaired_train, unimpaired_test = train_test_split(pIDs_unimpaired, test_size=test_size, random_state=42)\n",
    "\n",
    "    # Combine train and test users\n",
    "    training_users = impaired_train + unimpaired_train\n",
    "    test_users = impaired_test + unimpaired_test\n",
    "\n",
    "    metadata_cols = ['Participant', 'Gesture_ID', 'Gesture_Num']\n",
    "\n",
    "    # Split data by users\n",
    "    train_df = data_df[data_df['Participant'].isin(training_users)]\n",
    "    test_df = data_df[data_df['Participant'].isin(test_users)]\n",
    "\n",
    "    # Subset metadata columns for training and testing sets\n",
    "    train_metadata_df = train_df[metadata_cols].reset_index(drop=True)\n",
    "    test_metadata_df = test_df[metadata_cols].reset_index(drop=True)\n",
    "\n",
    "    # Drop metadata columns from the dataframes\n",
    "    train_df = train_df.drop(metadata_cols, axis=1).reset_index(drop=True)\n",
    "    test_df = test_df.drop(metadata_cols, axis=1).reset_index(drop=True)\n",
    "\n",
    "    # Scale the data\n",
    "    train_scaler = StandardScaler()\n",
    "\n",
    "    # Fit on training data and transform both train and test sets\n",
    "    ppd_train_df = pd.DataFrame(train_scaler.fit_transform(train_df))\n",
    "    ppd_test_df = pd.DataFrame(train_scaler.transform(test_df))\n",
    "\n",
    "    ppd_train_emg_df = ppd_train_df.iloc[:, 72:]\n",
    "    ppd_test_emg_df = ppd_test_df.iloc[:, 72:]\n",
    "\n",
    "    # Concatenate metadata back to the processed data\n",
    "    ppd_train_emg_df = pd.concat([train_metadata_df, ppd_train_emg_df], axis=1)\n",
    "    ppd_test_emg_df = pd.concat([test_metadata_df, ppd_test_emg_df], axis=1)\n",
    "\n",
    "    return ppd_train_emg_df, ppd_test_emg_df\n",
    "\n",
    "# Call the function with the full participant list\n",
    "ppd_train_emg_df, ppd_test_emg_df = split_and_preprocess_by_user(data_df, pIDs_impaired, pIDs_unimpaired)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a57853c-2c46-490e-9d30-565968c9f15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153600, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant</th>\n",
       "      <th>Gesture_ID</th>\n",
       "      <th>Gesture_Num</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P103</td>\n",
       "      <td>move</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.272553</td>\n",
       "      <td>-0.174909</td>\n",
       "      <td>-0.487032</td>\n",
       "      <td>-0.479092</td>\n",
       "      <td>-0.282206</td>\n",
       "      <td>-0.340962</td>\n",
       "      <td>-0.349967</td>\n",
       "      <td>-0.372957</td>\n",
       "      <td>-0.460476</td>\n",
       "      <td>-0.322696</td>\n",
       "      <td>-0.353601</td>\n",
       "      <td>-0.359954</td>\n",
       "      <td>-0.341444</td>\n",
       "      <td>-0.270736</td>\n",
       "      <td>-0.129773</td>\n",
       "      <td>-0.256569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P103</td>\n",
       "      <td>move</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.237541</td>\n",
       "      <td>-0.219476</td>\n",
       "      <td>-0.491541</td>\n",
       "      <td>-0.456715</td>\n",
       "      <td>-0.259345</td>\n",
       "      <td>-0.269619</td>\n",
       "      <td>-0.370232</td>\n",
       "      <td>-0.354646</td>\n",
       "      <td>-0.456982</td>\n",
       "      <td>-0.301867</td>\n",
       "      <td>-0.349724</td>\n",
       "      <td>-0.356034</td>\n",
       "      <td>-0.337765</td>\n",
       "      <td>-0.281176</td>\n",
       "      <td>-0.106944</td>\n",
       "      <td>-0.250600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P103</td>\n",
       "      <td>move</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.226202</td>\n",
       "      <td>-0.227727</td>\n",
       "      <td>-0.498172</td>\n",
       "      <td>-0.514807</td>\n",
       "      <td>-0.247238</td>\n",
       "      <td>-0.248624</td>\n",
       "      <td>-0.340924</td>\n",
       "      <td>-0.330598</td>\n",
       "      <td>-0.453981</td>\n",
       "      <td>-0.294390</td>\n",
       "      <td>-0.355787</td>\n",
       "      <td>-0.360192</td>\n",
       "      <td>-0.341552</td>\n",
       "      <td>-0.274673</td>\n",
       "      <td>-0.068181</td>\n",
       "      <td>-0.182230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P103</td>\n",
       "      <td>move</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.059969</td>\n",
       "      <td>-0.167775</td>\n",
       "      <td>-0.476214</td>\n",
       "      <td>-0.597320</td>\n",
       "      <td>-0.266217</td>\n",
       "      <td>-0.281169</td>\n",
       "      <td>-0.308048</td>\n",
       "      <td>-0.280282</td>\n",
       "      <td>-0.518521</td>\n",
       "      <td>-0.294813</td>\n",
       "      <td>-0.355749</td>\n",
       "      <td>-0.350663</td>\n",
       "      <td>-0.333018</td>\n",
       "      <td>-0.264322</td>\n",
       "      <td>-0.065513</td>\n",
       "      <td>-0.144634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P103</td>\n",
       "      <td>move</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.012488</td>\n",
       "      <td>-0.202698</td>\n",
       "      <td>-0.483415</td>\n",
       "      <td>-0.510942</td>\n",
       "      <td>-0.278117</td>\n",
       "      <td>-0.243418</td>\n",
       "      <td>-0.328787</td>\n",
       "      <td>-0.316063</td>\n",
       "      <td>-0.439284</td>\n",
       "      <td>-0.295585</td>\n",
       "      <td>-0.346027</td>\n",
       "      <td>-0.350198</td>\n",
       "      <td>-0.327595</td>\n",
       "      <td>-0.256635</td>\n",
       "      <td>-0.112046</td>\n",
       "      <td>-0.256429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Participant Gesture_ID Gesture_Num        72        73        74        75  \\\n",
       "0        P103       move           1 -0.272553 -0.174909 -0.487032 -0.479092   \n",
       "1        P103       move           1 -0.237541 -0.219476 -0.491541 -0.456715   \n",
       "2        P103       move           1 -0.226202 -0.227727 -0.498172 -0.514807   \n",
       "3        P103       move           1 -0.059969 -0.167775 -0.476214 -0.597320   \n",
       "4        P103       move           1 -0.012488 -0.202698 -0.483415 -0.510942   \n",
       "\n",
       "         76        77        78        79        80        81        82  \\\n",
       "0 -0.282206 -0.340962 -0.349967 -0.372957 -0.460476 -0.322696 -0.353601   \n",
       "1 -0.259345 -0.269619 -0.370232 -0.354646 -0.456982 -0.301867 -0.349724   \n",
       "2 -0.247238 -0.248624 -0.340924 -0.330598 -0.453981 -0.294390 -0.355787   \n",
       "3 -0.266217 -0.281169 -0.308048 -0.280282 -0.518521 -0.294813 -0.355749   \n",
       "4 -0.278117 -0.243418 -0.328787 -0.316063 -0.439284 -0.295585 -0.346027   \n",
       "\n",
       "         83        84        85        86        87  \n",
       "0 -0.359954 -0.341444 -0.270736 -0.129773 -0.256569  \n",
       "1 -0.356034 -0.337765 -0.281176 -0.106944 -0.250600  \n",
       "2 -0.360192 -0.341552 -0.274673 -0.068181 -0.182230  \n",
       "3 -0.350663 -0.333018 -0.264322 -0.065513 -0.144634  \n",
       "4 -0.350198 -0.327595 -0.256635 -0.112046 -0.256429  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ppd_train_emg_df.shape)\n",
    "ppd_train_emg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3af61c71-7c48-4408-b436-dee2ee09eb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class EMG_Dataset(Dataset):\n",
    "    def __init__(self, emg_df, num_channels_emg=16, time_units=64):\n",
    "        # Create labels array using only Gesture_ID from EMG data\n",
    "        self.labels = emg_df['Gesture_ID'].values\n",
    "        \n",
    "        # Exclude metadata columns and reshape the EMG \n",
    "        emg_data = emg_df.drop(['Participant', 'Gesture_ID', 'Gesture_Num'], axis=1).values\n",
    "\n",
    "        # EMG data processing: (num_samples, time_units, num_channels_emg)\n",
    "        num_samples_emg = len(emg_data) // time_units\n",
    "        self.emg_data = emg_data.reshape(num_samples_emg, time_units, num_channels_emg).transpose((0, 2, 1))\n",
    "\n",
    "        # Create a dictionary to map each unique Gesture_ID to an integer label\n",
    "        unique_labels = np.unique(self.labels)\n",
    "        self.label_map = {label: i for i, label in enumerate(unique_labels)}\n",
    "        \n",
    "        # Map labels to integers\n",
    "        self.labels = np.array([self.label_map[label] for label in self.labels[:num_samples_emg * time_units:time_units]])\n",
    "\n",
    "        # Create a dictionary to map (Participant, Gesture_ID, Gesture_Num) to index\n",
    "        self.index_map = {(row['Participant'], row['Gesture_ID'], row['Gesture_Num']): idx // time_units \n",
    "                          for idx, row in emg_df.iterrows()}\n",
    "\n",
    "        # Sanity check\n",
    "        print(f\"EMG Data shape: {self.emg_data.shape}\")\n",
    "        print(f\"Labels shape: {self.labels.shape}\")\n",
    "        print(f\"Label mapping: {self.label_map}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.emg_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, tuple):\n",
    "            # Get item by (Participant, Gesture_ID, Gesture_Num)\n",
    "            idx = self.index_map[idx]\n",
    "        \n",
    "        emg_data = torch.tensor(self.emg_data[idx], dtype=torch.float32)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        \n",
    "        return emg_data, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "484d838b-8e78-43b2-86e8-c537d14d7df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMG Data shape: (2400, 16, 64)\n",
      "Labels shape: (2400,)\n",
      "Label mapping: {'close': 0, 'delete': 1, 'duplicate': 2, 'move': 3, 'open': 4, 'pan': 5, 'rotate': 6, 'select-single': 7, 'zoom-in': 8, 'zoom-out': 9}\n",
      "EMG Data shape: (800, 16, 64)\n",
      "Labels shape: (800,)\n",
      "Label mapping: {'close': 0, 'delete': 1, 'duplicate': 2, 'move': 3, 'open': 4, 'pan': 5, 'rotate': 6, 'select-single': 7, 'zoom-in': 8, 'zoom-out': 9}\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create dataset instances\n",
    "train_dataset = EMG_Dataset(ppd_train_emg_df)\n",
    "test_dataset = EMG_Dataset(ppd_test_emg_df)\n",
    "\n",
    "# Create DataLoader instances\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e48c7ff-173d-4758-a37c-c318fb16c5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class EMG_CNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(EMG_CNN, self).__init__()\n",
    "        \n",
    "        # Convolutional Block for EMG Data (16 channels)\n",
    "        self.emg_conv1 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "        self.emg_conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.emg_conv3 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "\n",
    "        # Fully connected layers after concatenation\n",
    "        # Flattened size of EMG (128 * 8)\n",
    "        self.fc1 = nn.Linear(128 * 8, 256)  \n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, emg_input):\n",
    "        # Forward pass for EMG data\n",
    "        x = torch.relu(self.emg_conv1(emg_input))\n",
    "        x = self.pool(x)\n",
    "        x = torch.relu(self.emg_conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.relu(self.emg_conv3(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # Flatten EMG outputs\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "\n",
    "\n",
    "        # Pass through the fully connected layers\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8a02957-6923-4447-9139-d0d9c53c9870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, dataloader, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for emg_data, labels in dataloader:\n",
    "        # Move EMG data, and labels to the device (GPU or CPU)\n",
    "        emg_data, labels = emg_data.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass with both EMG\n",
    "        outputs = model(emg_data)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update running loss\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Compute accuracy\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    # Calculate final accuracy for the epoch\n",
    "    accuracy = 100. * correct / total\n",
    "    return running_loss / len(dataloader), accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9075ba61-59a0-457f-bd2d-7570ff7549da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for emg_data, labels in dataloader:\n",
    "            # Move EMG data and labels to the device (GPU or CPU)\n",
    "            emg_data, labels = emg_data.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(emg_data)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Update running loss\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Compute accuracy\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    # Compute accuracy over the whole dataset\n",
    "    accuracy = 100. * correct / total\n",
    "    return running_loss / len(dataloader), accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8581741-2b3c-49d7-9617-e89c4d182065",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs, device):   \n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Train the model for one epoch\n",
    "        train_loss, train_acc = train(model, optimizer, train_loader, criterion, device)\n",
    "\n",
    "        end_time = time.time()\n",
    "        epoch_time = end_time - start_time\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"Epoch Time: {epoch_time:.2f} seconds\")\n",
    "        test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "        print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16a51b8b-820c-4fbf-ad98-c7f9ae48ef66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Train Loss: 2.3008, Train Acc: 11.33%\n",
      "Epoch Time: 0.24 seconds\n",
      "Test Loss: 2.3053, Test Acc: 10.00%\n",
      "Epoch 2/100\n",
      "Train Loss: 2.2889, Train Acc: 15.00%\n",
      "Epoch Time: 0.21 seconds\n",
      "Test Loss: 2.3524, Test Acc: 11.00%\n",
      "Epoch 3/100\n",
      "Train Loss: 2.2561, Train Acc: 18.67%\n",
      "Epoch Time: 0.19 seconds\n",
      "Test Loss: 2.6463, Test Acc: 12.38%\n",
      "Epoch 4/100\n",
      "Train Loss: 2.1931, Train Acc: 19.46%\n",
      "Epoch Time: 0.17 seconds\n",
      "Test Loss: 3.0900, Test Acc: 12.88%\n",
      "Epoch 5/100\n",
      "Train Loss: 2.1198, Train Acc: 21.17%\n",
      "Epoch Time: 0.18 seconds\n",
      "Test Loss: 3.5506, Test Acc: 12.62%\n",
      "Epoch 6/100\n",
      "Train Loss: 2.0539, Train Acc: 23.83%\n",
      "Epoch Time: 0.17 seconds\n",
      "Test Loss: 3.8807, Test Acc: 13.12%\n",
      "Epoch 7/100\n",
      "Train Loss: 1.9959, Train Acc: 26.50%\n",
      "Epoch Time: 0.17 seconds\n",
      "Test Loss: 4.6750, Test Acc: 12.75%\n",
      "Epoch 8/100\n",
      "Train Loss: 1.9420, Train Acc: 27.88%\n",
      "Epoch Time: 0.20 seconds\n",
      "Test Loss: 4.9501, Test Acc: 12.38%\n",
      "Epoch 9/100\n",
      "Train Loss: 1.9047, Train Acc: 28.79%\n",
      "Epoch Time: 0.19 seconds\n",
      "Test Loss: 5.4278, Test Acc: 10.62%\n",
      "Epoch 10/100\n",
      "Train Loss: 1.8605, Train Acc: 29.62%\n",
      "Epoch Time: 0.19 seconds\n",
      "Test Loss: 6.4649, Test Acc: 14.38%\n",
      "Epoch 11/100\n",
      "Train Loss: 1.8242, Train Acc: 31.62%\n",
      "Epoch Time: 0.19 seconds\n",
      "Test Loss: 6.6963, Test Acc: 11.62%\n",
      "Epoch 12/100\n",
      "Train Loss: 1.7839, Train Acc: 32.50%\n",
      "Epoch Time: 0.20 seconds\n",
      "Test Loss: 7.1073, Test Acc: 12.38%\n",
      "Epoch 13/100\n",
      "Train Loss: 1.7479, Train Acc: 34.96%\n",
      "Epoch Time: 0.19 seconds\n",
      "Test Loss: 7.7005, Test Acc: 12.75%\n",
      "Epoch 14/100\n",
      "Train Loss: 1.7143, Train Acc: 36.29%\n",
      "Epoch Time: 0.19 seconds\n",
      "Test Loss: 8.0022, Test Acc: 12.62%\n",
      "Epoch 15/100\n",
      "Train Loss: 1.6836, Train Acc: 36.46%\n",
      "Epoch Time: 0.18 seconds\n",
      "Test Loss: 9.1771, Test Acc: 13.12%\n",
      "Epoch 16/100\n",
      "Train Loss: 1.6455, Train Acc: 38.08%\n",
      "Epoch Time: 0.17 seconds\n",
      "Test Loss: 8.9685, Test Acc: 13.50%\n",
      "Epoch 17/100\n",
      "Train Loss: 1.6151, Train Acc: 38.88%\n",
      "Epoch Time: 0.17 seconds\n",
      "Test Loss: 9.6628, Test Acc: 13.25%\n",
      "Epoch 18/100\n",
      "Train Loss: 1.5798, Train Acc: 41.38%\n",
      "Epoch Time: 0.17 seconds\n",
      "Test Loss: 9.9587, Test Acc: 12.88%\n",
      "Epoch 19/100\n",
      "Train Loss: 1.5547, Train Acc: 42.67%\n",
      "Epoch Time: 0.19 seconds\n",
      "Test Loss: 10.5913, Test Acc: 13.50%\n",
      "Epoch 20/100\n",
      "Train Loss: 1.5310, Train Acc: 43.62%\n",
      "Epoch Time: 0.18 seconds\n",
      "Test Loss: 11.7939, Test Acc: 13.38%\n",
      "Epoch 21/100\n",
      "Train Loss: 1.4933, Train Acc: 46.71%\n",
      "Epoch Time: 0.17 seconds\n",
      "Test Loss: 13.4139, Test Acc: 12.50%\n",
      "Epoch 22/100\n",
      "Train Loss: 1.4778, Train Acc: 47.38%\n",
      "Epoch Time: 0.17 seconds\n",
      "Test Loss: 10.3267, Test Acc: 13.88%\n",
      "Epoch 23/100\n",
      "Train Loss: 1.4507, Train Acc: 47.50%\n",
      "Epoch Time: 0.17 seconds\n",
      "Test Loss: 10.4836, Test Acc: 14.00%\n",
      "Epoch 24/100\n",
      "Train Loss: 1.4201, Train Acc: 49.12%\n",
      "Epoch Time: 0.18 seconds\n",
      "Test Loss: 11.8996, Test Acc: 14.88%\n",
      "Epoch 25/100\n",
      "Train Loss: 1.3900, Train Acc: 50.75%\n",
      "Epoch Time: 0.17 seconds\n",
      "Test Loss: 12.8023, Test Acc: 14.25%\n",
      "Epoch 26/100\n",
      "Train Loss: 1.3765, Train Acc: 51.25%\n",
      "Epoch Time: 0.17 seconds\n",
      "Test Loss: 13.1604, Test Acc: 14.12%\n",
      "Epoch 27/100\n",
      "Train Loss: 1.3444, Train Acc: 52.54%\n",
      "Epoch Time: 0.18 seconds\n",
      "Test Loss: 12.9044, Test Acc: 14.00%\n",
      "Epoch 28/100\n",
      "Train Loss: 1.3254, Train Acc: 53.96%\n",
      "Epoch Time: 0.17 seconds\n",
      "Test Loss: 13.2981, Test Acc: 13.88%\n",
      "Epoch 29/100\n",
      "Train Loss: 1.3161, Train Acc: 52.83%\n",
      "Epoch Time: 0.20 seconds\n",
      "Test Loss: 12.5789, Test Acc: 12.75%\n",
      "Epoch 30/100\n",
      "Train Loss: 1.2615, Train Acc: 56.33%\n",
      "Epoch Time: 0.20 seconds\n",
      "Test Loss: 14.3784, Test Acc: 14.38%\n",
      "Epoch 31/100\n",
      "Train Loss: 1.2433, Train Acc: 56.62%\n",
      "Epoch Time: 0.18 seconds\n",
      "Test Loss: 14.7592, Test Acc: 14.38%\n",
      "Epoch 32/100\n",
      "Train Loss: 1.2251, Train Acc: 57.71%\n",
      "Epoch Time: 0.19 seconds\n",
      "Test Loss: 15.7355, Test Acc: 13.62%\n",
      "Epoch 33/100\n",
      "Train Loss: 1.2014, Train Acc: 58.38%\n",
      "Epoch Time: 0.19 seconds\n",
      "Test Loss: 13.4089, Test Acc: 14.25%\n",
      "Epoch 34/100\n",
      "Train Loss: 1.1763, Train Acc: 58.83%\n",
      "Epoch Time: 0.18 seconds\n",
      "Test Loss: 14.5919, Test Acc: 15.38%\n",
      "Epoch 35/100\n",
      "Train Loss: 1.1620, Train Acc: 59.42%\n",
      "Epoch Time: 0.21 seconds\n",
      "Test Loss: 14.0649, Test Acc: 14.38%\n",
      "Epoch 36/100\n",
      "Train Loss: 1.1358, Train Acc: 60.62%\n",
      "Epoch Time: 0.18 seconds\n",
      "Test Loss: 14.8628, Test Acc: 14.88%\n",
      "Epoch 37/100\n",
      "Train Loss: 1.1129, Train Acc: 61.17%\n",
      "Epoch Time: 0.20 seconds\n",
      "Test Loss: 16.3051, Test Acc: 15.25%\n",
      "Epoch 38/100\n",
      "Train Loss: 1.0891, Train Acc: 62.58%\n",
      "Epoch Time: 0.18 seconds\n",
      "Test Loss: 16.2139, Test Acc: 14.88%\n",
      "Epoch 39/100\n",
      "Train Loss: 1.0725, Train Acc: 63.17%\n",
      "Epoch Time: 0.19 seconds\n",
      "Test Loss: 17.4283, Test Acc: 15.38%\n",
      "Epoch 40/100\n",
      "Train Loss: 1.0530, Train Acc: 64.38%\n",
      "Epoch Time: 0.18 seconds\n",
      "Test Loss: 16.7944, Test Acc: 14.88%\n",
      "Epoch 41/100\n",
      "Train Loss: 1.0317, Train Acc: 64.54%\n",
      "Epoch Time: 0.17 seconds\n",
      "Test Loss: 17.7592, Test Acc: 14.88%\n",
      "Epoch 42/100\n",
      "Train Loss: 1.0190, Train Acc: 65.33%\n",
      "Epoch Time: 0.19 seconds\n",
      "Test Loss: 16.9375, Test Acc: 15.50%\n",
      "Epoch 43/100\n",
      "Train Loss: 0.9948, Train Acc: 66.33%\n",
      "Epoch Time: 0.18 seconds\n",
      "Test Loss: 17.3113, Test Acc: 15.38%\n",
      "Epoch 44/100\n",
      "Train Loss: 0.9852, Train Acc: 65.75%\n",
      "Epoch Time: 0.17 seconds\n",
      "Test Loss: 17.3767, Test Acc: 14.88%\n",
      "Epoch 45/100\n",
      "Train Loss: 0.9789, Train Acc: 66.21%\n",
      "Epoch Time: 0.20 seconds\n",
      "Test Loss: 18.5841, Test Acc: 15.38%\n",
      "Epoch 46/100\n",
      "Train Loss: 0.9506, Train Acc: 69.33%\n",
      "Epoch Time: 0.17 seconds\n",
      "Test Loss: 18.5409, Test Acc: 14.88%\n",
      "Epoch 47/100\n",
      "Train Loss: 0.9295, Train Acc: 69.25%\n",
      "Epoch Time: 0.17 seconds\n",
      "Test Loss: 18.4587, Test Acc: 15.12%\n",
      "Epoch 48/100\n",
      "Train Loss: 0.9209, Train Acc: 69.71%\n",
      "Epoch Time: 0.19 seconds\n",
      "Test Loss: 18.7342, Test Acc: 14.38%\n",
      "Epoch 49/100\n",
      "Train Loss: 0.9086, Train Acc: 69.83%\n",
      "Epoch Time: 0.18 seconds\n",
      "Test Loss: 19.3635, Test Acc: 15.00%\n",
      "Epoch 50/100\n",
      "Train Loss: 0.8829, Train Acc: 71.12%\n",
      "Epoch Time: 0.18 seconds\n",
      "Test Loss: 20.8317, Test Acc: 16.00%\n",
      "Epoch 51/100\n",
      "Train Loss: 0.8688, Train Acc: 71.67%\n",
      "Epoch Time: 0.18 seconds\n",
      "Test Loss: 21.6256, Test Acc: 14.88%\n",
      "Epoch 52/100\n",
      "Train Loss: 0.8569, Train Acc: 72.29%\n",
      "Epoch Time: 0.19 seconds\n",
      "Test Loss: 19.8825, Test Acc: 14.75%\n",
      "Epoch 53/100\n",
      "Train Loss: 0.8390, Train Acc: 72.21%\n",
      "Epoch Time: 0.17 seconds\n",
      "Test Loss: 20.3565, Test Acc: 14.88%\n",
      "Epoch 54/100\n",
      "Train Loss: 0.8349, Train Acc: 72.92%\n",
      "Epoch Time: 0.17 seconds\n",
      "Test Loss: 19.9411, Test Acc: 13.88%\n",
      "Epoch 55/100\n",
      "Train Loss: 0.8196, Train Acc: 73.17%\n",
      "Epoch Time: 0.17 seconds\n",
      "Test Loss: 19.6820, Test Acc: 14.38%\n",
      "Epoch 56/100\n",
      "Train Loss: 0.8010, Train Acc: 73.62%\n",
      "Epoch Time: 0.20 seconds\n",
      "Test Loss: 20.5628, Test Acc: 15.12%\n",
      "Epoch 57/100\n",
      "Train Loss: 0.7935, Train Acc: 74.33%\n",
      "Epoch Time: 0.21 seconds\n",
      "Test Loss: 24.0266, Test Acc: 15.62%\n",
      "Epoch 58/100\n",
      "Train Loss: 0.7891, Train Acc: 74.29%\n",
      "Epoch Time: 0.19 seconds\n",
      "Test Loss: 21.6259, Test Acc: 15.00%\n",
      "Epoch 59/100\n",
      "Train Loss: 0.7839, Train Acc: 73.96%\n",
      "Epoch Time: 0.20 seconds\n",
      "Test Loss: 22.5022, Test Acc: 15.00%\n",
      "Epoch 60/100\n",
      "Train Loss: 0.7596, Train Acc: 75.42%\n",
      "Epoch Time: 0.20 seconds\n",
      "Test Loss: 23.0216, Test Acc: 15.25%\n",
      "Epoch 61/100\n",
      "Train Loss: 0.7416, Train Acc: 76.17%\n",
      "Epoch Time: 0.20 seconds\n",
      "Test Loss: 24.5588, Test Acc: 15.62%\n",
      "Epoch 62/100\n",
      "Train Loss: 0.7413, Train Acc: 76.62%\n",
      "Epoch Time: 0.18 seconds\n",
      "Test Loss: 23.7725, Test Acc: 16.12%\n",
      "Epoch 63/100\n",
      "Train Loss: 0.7165, Train Acc: 76.62%\n",
      "Epoch Time: 0.17 seconds\n",
      "Test Loss: 23.6658, Test Acc: 15.38%\n",
      "Epoch 64/100\n",
      "Train Loss: 0.7111, Train Acc: 77.67%\n",
      "Epoch Time: 0.20 seconds\n",
      "Test Loss: 24.5224, Test Acc: 15.62%\n",
      "Epoch 65/100\n",
      "Train Loss: 0.6997, Train Acc: 77.46%\n",
      "Epoch Time: 0.19 seconds\n",
      "Test Loss: 24.9088, Test Acc: 15.25%\n",
      "Epoch 66/100\n",
      "Train Loss: 0.6944, Train Acc: 77.83%\n",
      "Epoch Time: 0.20 seconds\n",
      "Test Loss: 24.8694, Test Acc: 16.00%\n",
      "Epoch 67/100\n",
      "Train Loss: 0.6736, Train Acc: 78.38%\n",
      "Epoch Time: 0.18 seconds\n",
      "Test Loss: 26.6108, Test Acc: 16.25%\n",
      "Epoch 68/100\n",
      "Train Loss: 0.6654, Train Acc: 78.79%\n",
      "Epoch Time: 0.19 seconds\n",
      "Test Loss: 27.2420, Test Acc: 16.38%\n",
      "Epoch 69/100\n",
      "Train Loss: 0.6609, Train Acc: 78.08%\n",
      "Epoch Time: 0.20 seconds\n",
      "Test Loss: 29.3009, Test Acc: 15.88%\n",
      "Epoch 70/100\n",
      "Train Loss: 0.6588, Train Acc: 79.21%\n",
      "Epoch Time: 0.20 seconds\n",
      "Test Loss: 26.0808, Test Acc: 15.00%\n",
      "Epoch 71/100\n",
      "Train Loss: 0.6434, Train Acc: 79.42%\n",
      "Epoch Time: 0.19 seconds\n",
      "Test Loss: 29.6350, Test Acc: 15.88%\n",
      "Epoch 72/100\n",
      "Train Loss: 0.6293, Train Acc: 79.83%\n",
      "Epoch Time: 0.19 seconds\n",
      "Test Loss: 29.7628, Test Acc: 16.25%\n",
      "Epoch 73/100\n",
      "Train Loss: 0.6237, Train Acc: 79.92%\n",
      "Epoch Time: 0.19 seconds\n",
      "Test Loss: 30.4289, Test Acc: 15.62%\n",
      "Epoch 74/100\n",
      "Train Loss: 0.6184, Train Acc: 80.25%\n",
      "Epoch Time: 0.19 seconds\n",
      "Test Loss: 31.2388, Test Acc: 15.12%\n",
      "Epoch 75/100\n",
      "Train Loss: 0.6077, Train Acc: 81.00%\n",
      "Epoch Time: 0.21 seconds\n",
      "Test Loss: 31.5774, Test Acc: 15.38%\n",
      "Epoch 76/100\n",
      "Train Loss: 0.6227, Train Acc: 79.58%\n",
      "Epoch Time: 0.19 seconds\n",
      "Test Loss: 30.2394, Test Acc: 15.12%\n",
      "Epoch 77/100\n",
      "Train Loss: 0.5933, Train Acc: 80.25%\n",
      "Epoch Time: 0.19 seconds\n",
      "Test Loss: 31.1391, Test Acc: 15.00%\n",
      "Epoch 78/100\n",
      "Train Loss: 0.5827, Train Acc: 81.96%\n",
      "Epoch Time: 0.19 seconds\n",
      "Test Loss: 33.8578, Test Acc: 15.88%\n",
      "Epoch 79/100\n",
      "Train Loss: 0.5772, Train Acc: 80.88%\n",
      "Epoch Time: 0.19 seconds\n",
      "Test Loss: 33.4771, Test Acc: 15.25%\n",
      "Epoch 80/100\n",
      "Train Loss: 0.5647, Train Acc: 81.88%\n",
      "Epoch Time: 0.19 seconds\n",
      "Test Loss: 35.5168, Test Acc: 15.25%\n",
      "Epoch 81/100\n",
      "Train Loss: 0.5713, Train Acc: 82.00%\n",
      "Epoch Time: 0.19 seconds\n",
      "Test Loss: 36.5823, Test Acc: 15.38%\n",
      "Epoch 82/100\n",
      "Train Loss: 0.5589, Train Acc: 81.62%\n",
      "Epoch Time: 0.19 seconds\n",
      "Test Loss: 35.0846, Test Acc: 15.00%\n",
      "Epoch 83/100\n",
      "Train Loss: 0.5417, Train Acc: 82.50%\n",
      "Epoch Time: 0.17 seconds\n",
      "Test Loss: 35.0602, Test Acc: 15.50%\n",
      "Epoch 84/100\n",
      "Train Loss: 0.5357, Train Acc: 82.67%\n",
      "Epoch Time: 0.17 seconds\n",
      "Test Loss: 37.1858, Test Acc: 15.12%\n",
      "Epoch 85/100\n",
      "Train Loss: 0.5231, Train Acc: 83.29%\n",
      "Epoch Time: 0.19 seconds\n",
      "Test Loss: 37.4339, Test Acc: 15.75%\n",
      "Epoch 86/100\n",
      "Train Loss: 0.5139, Train Acc: 83.88%\n",
      "Epoch Time: 0.17 seconds\n",
      "Test Loss: 37.6966, Test Acc: 15.88%\n",
      "Epoch 87/100\n",
      "Train Loss: 0.5140, Train Acc: 83.46%\n",
      "Epoch Time: 0.18 seconds\n",
      "Test Loss: 41.5899, Test Acc: 16.12%\n",
      "Epoch 88/100\n",
      "Train Loss: 0.5116, Train Acc: 83.83%\n",
      "Epoch Time: 0.18 seconds\n",
      "Test Loss: 41.1657, Test Acc: 15.62%\n",
      "Epoch 89/100\n",
      "Train Loss: 0.5042, Train Acc: 83.88%\n",
      "Epoch Time: 0.18 seconds\n",
      "Test Loss: 39.5370, Test Acc: 15.00%\n",
      "Epoch 90/100\n",
      "Train Loss: 0.4897, Train Acc: 84.83%\n",
      "Epoch Time: 0.19 seconds\n",
      "Test Loss: 40.6489, Test Acc: 15.12%\n",
      "Epoch 91/100\n",
      "Train Loss: 0.4893, Train Acc: 84.08%\n",
      "Epoch Time: 0.18 seconds\n",
      "Test Loss: 44.1943, Test Acc: 15.25%\n",
      "Epoch 92/100\n",
      "Train Loss: 0.5034, Train Acc: 83.54%\n",
      "Epoch Time: 0.17 seconds\n",
      "Test Loss: 41.6633, Test Acc: 15.25%\n",
      "Epoch 93/100\n",
      "Train Loss: 0.4810, Train Acc: 85.04%\n",
      "Epoch Time: 0.17 seconds\n",
      "Test Loss: 43.6208, Test Acc: 15.50%\n",
      "Epoch 94/100\n",
      "Train Loss: 0.4613, Train Acc: 85.67%\n",
      "Epoch Time: 0.18 seconds\n",
      "Test Loss: 42.6327, Test Acc: 14.75%\n",
      "Epoch 95/100\n",
      "Train Loss: 0.4574, Train Acc: 85.17%\n",
      "Epoch Time: 0.19 seconds\n",
      "Test Loss: 45.1612, Test Acc: 15.38%\n",
      "Epoch 96/100\n",
      "Train Loss: 0.4547, Train Acc: 85.96%\n",
      "Epoch Time: 0.17 seconds\n",
      "Test Loss: 45.2873, Test Acc: 15.38%\n",
      "Epoch 97/100\n",
      "Train Loss: 0.4422, Train Acc: 86.50%\n",
      "Epoch Time: 0.18 seconds\n",
      "Test Loss: 46.1612, Test Acc: 15.38%\n",
      "Epoch 98/100\n",
      "Train Loss: 0.4402, Train Acc: 85.79%\n",
      "Epoch Time: 0.19 seconds\n",
      "Test Loss: 46.1514, Test Acc: 15.50%\n",
      "Epoch 99/100\n",
      "Train Loss: 0.4328, Train Acc: 87.04%\n",
      "Epoch Time: 0.19 seconds\n",
      "Test Loss: 47.0309, Test Acc: 15.25%\n",
      "Epoch 100/100\n",
      "Train Loss: 0.4250, Train Acc: 86.67%\n",
      "Epoch Time: 0.19 seconds\n",
      "Test Loss: 48.7526, Test Acc: 15.12%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize EMG_CNN model and move it to the device\n",
    "emg_model = EMG_CNN().to(device)\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 100\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(emg_model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "\n",
    "# Train the EMG model\n",
    "train_model(emg_model, train_loader, test_loader, criterion, optimizer, num_epochs, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50fd19c-54a3-475f-a320-44b7a98a04a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
